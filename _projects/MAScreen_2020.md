---
title: MAScreen
subtitle: 'Augmenting Speech with Visual Cues of Lip Motions, Facial Expressions, and Text Using a Wearable Display'
description: 'MAScreen: Augmenting Speech with Visual Cues of Lip Motions, Facial Expressions, and Text Using a Wearable Display'
year: 2020
featured_image: /images/projects/mascreen.jpg # width must be 1600px
pdf_file: Lee_MAScreen_SiggraphAsiaET20.pdf # put file in the directory FILES
doi_link: https://doi.org/10.1145/3415255.3422886
featured: true
---

<iframe width="560" height="315" src="https://www.youtube.com/embed/EapuK9xQDLI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<!-- DO NOT CHANGE MANUALLY -->

# {{page.title}}: {{page.subtitle}} ({{page.year}}) 

Personal protective equipment, particularly face masks, have be- come increasingly common with the rise of global health issues, such as fine-dust storms and pandemics. Face masks, however, also degrade speech intelligibility by effectively occluding visual cues, such as lip motions and facial expressions. In this paper, we propose MAScreen, a wearable LED display in the shape of a mask, which is capable of sensing lip motion and speech and provides real-time visual feedback of the mouth behind the mask.

### References

Hyein Lee, Yoonji Kim, and Andrea Bianchi. 2020. **MAScreen: Augmenting Speech with Visual Cues of Lip Motions, Facial Expressions, and Text Using a Wearable Display**. In SIGGRAPH Asia 2020 Emerging Technologies (SA '20). Association for Computing Machinery, New York, NY, USA, Article 2, 1â€“2. DOI:https://doi.org/10.1145/3415255.3422886


<!-- DO NOT CHANGE MANUALLY -->

<a href="{{ site.url }}/files/{{ page.year }}/{{ page.pdf_file }}" target="_blank">paper</a>&nbsp;&nbsp;&nbsp;
<a href="{{ page.doi_link }}" target="_blank">doi</a>

---

<a href="/index.html" class="button button--large">Back to projects</a>
